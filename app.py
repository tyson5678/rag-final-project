import streamlit as st
import os
import sys
import tempfile
import uuid

# ================= 1. é›²ç«¯è³‡æ–™åº«ä¿®æ­£ =================
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

# ================= 2. é é¢è¨­å®š =================
st.set_page_config(
    page_title="AI æ™ºèƒ½æŠ•è³‡åˆ†æå¸«", 
    page_icon="ğŸ“ˆ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“ˆ AI æ™ºèƒ½æŠ•è³‡åˆ†æå¸«")
st.caption("ğŸš€ æ•´åˆå³æ™‚è‚¡åƒ¹ (Yahoo Finance) + ç¶²è·¯æ–°è + è²¡å ±æ·±åº¦åˆ†æ (RAG)")

# ================= 3. åŒ¯å…¥å¿…è¦å¥—ä»¶ =================
try:
    import langchain
    from langchain_groq import ChatGroq
    from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    # ğŸŒŸ ä½¿ç”¨ FastEmbed é¿å…é›²ç«¯ç•¶æ©Ÿ
    from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
    from langchain_chroma import Chroma
    from langchain_core.prompts import ChatPromptTemplate
    # ğŸŒŸ é€™äº›æ˜¯æ–°ç‰ˆ LangChain çš„åŠŸèƒ½ï¼Œrequirements.txt å¿…é ˆ >=0.2.0
    from langchain.agents import create_tool_calling_agent, AgentExecutor
    from langchain_core.tools import tool
    from langchain.tools.retriever import create_retriever_tool
    from langchain_community.tools import DuckDuckGoSearchRun
    import yfinance as yf
    
except ImportError as e:
    st.error(f"âŒ ç³»çµ±å•Ÿå‹•å¤±æ•—ï¼åŸå› : {e}")
    st.stop()

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ================= 4. API Key =================
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
except:
    GROQ_API_KEY = "è«‹å¡«å…¥Key"

# ================= 5. å®šç¾©å·¥å…· (Tools) =================

@tool
def get_stock_price(symbol: str):
    """
    ç²å–è‚¡ç¥¨çš„å³æ™‚è‚¡åƒ¹è³‡è¨Šã€‚
    è¼¸å…¥åƒæ•¸ symbol å¿…é ˆæ˜¯è‚¡ç¥¨ä»£ç¢¼ã€‚
    å°è‚¡è«‹åŠ ä¸Š .TW (ä¾‹å¦‚ 2330.TW)ï¼Œç¾è‚¡ç›´æ¥è¼¸å…¥ä»£ç¢¼ (ä¾‹å¦‚ NVDA, AAPL)ã€‚
    """
    try:
        stock = yf.Ticker(symbol)
        info = stock.info
        current_price = info.get('currentPrice', 'N/A')
        currency = info.get('currency', 'USD')
        pe_ratio = info.get('trailingPE', 'N/A')
        market_cap = info.get('marketCap', 'N/A')
        return f"ã€{symbol} å³æ™‚æ•¸æ“šã€‘\nç¾åƒ¹: {current_price} {currency}\næœ¬ç›Šæ¯”(P/E): {pe_ratio}\nå¸‚å€¼: {market_cap}"
    except Exception as e:
        return f"æŸ¥è©¢å¤±æ•—: {e}"

@tool
def get_company_news(query: str):
    """
    æœå°‹é—œæ–¼è©²å…¬å¸çš„æœ€æ–°ç¶²è·¯æ–°èæˆ–å¸‚å ´æ¶ˆæ¯ã€‚
    """
    search = DuckDuckGoSearchRun()
    return search.run(query)

# ================= 6. æ ¸å¿ƒé‚è¼¯ =================

if "uploader_id" not in st.session_state:
    st.session_state.uploader_id = str(uuid.uuid4())
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vector_db" not in st.session_state:
    st.session_state.vector_db = None
if "processed_files" not in st.session_state:
    st.session_state.processed_files = [] 

def nuke_reset():
    """æ ¸å½ˆç´šé‡ç½®"""
    st.session_state.messages = []
    st.session_state.vector_db = None
    st.session_state.processed_files = []
    st.session_state.uploader_id = str(uuid.uuid4()) 

with st.sidebar:
    st.header("ğŸ—‚ï¸ è²¡å ±/æ–‡ä»¶ä¸Šå‚³")
    
    uploaded_files = st.file_uploader(
        "ä¸Šå‚³æ–‡ä»¶", 
        type=["pdf", "docx"], 
        accept_multiple_files=True,
        key=st.session_state.uploader_id 
    )
    
    current_files_sig = [(f.name, f.size) for f in uploaded_files] if uploaded_files else []
    
    if uploaded_files:
        if current_files_sig != st.session_state.processed_files:
            with st.spinner("ğŸ§  æ­£åœ¨è®€å–è²¡å ±æ•¸æ“š (FastEmbed)..."):
                try:
                    all_splits = []
                    for uploaded_file in uploaded_files:
                        file_name = uploaded_file.name
                        file_ext = os.path.splitext(file_name)[1].lower()
                        
                        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
                            tmp_file.write(uploaded_file.getvalue())
                            tmp_path = tmp_file.name

                        if file_ext == ".pdf":
                            loader = PyPDFLoader(tmp_path)
                        elif file_ext == ".docx":
                            loader = Docx2txtLoader(tmp_path)
                        else:
                            continue
                            
                        docs = loader.load()
                        # Agent æ¨¡å¼ä¸‹ï¼Œåˆ‡åˆ†å¯ä»¥ç¨å¾®å°ä¸€é»ï¼Œè®“æª¢ç´¢æ›´ç²¾æº–
                        text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)
                        splits = text_splitter.split_documents(docs)
                        all_splits.extend(splits)
                        os.remove(tmp_path)

                    if all_splits:
                        # ğŸŒŸ ä½¿ç”¨ FastEmbed (è¼•é‡ã€CPUå°ˆç”¨)
                        embeddings = FastEmbedEmbeddings()
                        unique_collection_name = f"collection_{uuid.uuid4()}"
                        
                        vector_db = Chroma.from_documents(
                            documents=all_splits, 
                            embedding=embeddings,
                            collection_name=unique_collection_name 
                        )
                        
                        st.session_state.vector_db = vector_db
                        st.session_state.processed_files = current_files_sig
                        st.toast(f"âœ… è²¡å ±è³‡æ–™åº«å»ºç«‹å®Œæˆï¼", icon="ğŸ“Š")
                    else:
                        st.warning("âš ï¸ æª”æ¡ˆå…§å®¹ç‚ºç©º")
                except Exception as e:
                    st.error(f"âŒ éŒ¯èª¤: {e}")
    else:
        if st.session_state.vector_db is not None:
            st.session_state.vector_db = None
            st.session_state.processed_files = []
            st.rerun()

    st.divider()
    st.markdown("### ğŸ’¡ ä½¿ç”¨ç¯„ä¾‹")
    st.markdown("- æŸ¥è‚¡åƒ¹ï¼š`2330.TW è‚¡åƒ¹`")
    st.markdown("- æŸ¥æ–°èï¼š`NVDA æœ€æ–°æ–°è`")
    st.markdown("- ç¶œåˆï¼š(éœ€ä¸Šå‚³) `çµåˆè‚¡åƒ¹åˆ†æé€™ä»½è²¡å ±`")
    
    st.markdown("") 
    if st.button("ğŸ”„ é‡ç½®ç³»çµ±", type="primary", use_container_width=True, on_click=nuke_reset):
        pass

# ================= èŠå¤©ä»‹é¢ =================

if not st.session_state.messages:
    st.info("ğŸ‘‹ æˆ‘æ˜¯ AI æŠ•è³‡åˆ†æå¸«ï¼Œè«‹ä¸‹é”æŒ‡ä»¤ã€‚")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è«‹è¼¸å…¥å•é¡Œ..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("ğŸ¤” AI æ­£åœ¨æ€è€ƒèˆ‡èª¿ç”¨å·¥å…·...")
        
        try:
            llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name="llama-3.3-70b-versatile", temperature=0.1)
            
            # å®šç¾©å·¥å…·
            tools = [get_stock_price, get_company_news]
            
            # å¦‚æœæœ‰ RAG è³‡æ–™åº«ï¼ŒåŠ å…¥æª¢ç´¢å·¥å…·
            if st.session_state.vector_db:
                retriever = st.session_state.vector_db.as_retriever(search_kwargs={"k": 5})
                retriever_tool = create_retriever_tool(
                    retriever,
                    "search_financial_report",
                    "æœå°‹ä½¿ç”¨è€…ä¸Šå‚³çš„è²¡å ±å…§å®¹ã€‚ç•¶å•é¡Œæ¶‰åŠå…¬å¸å…§éƒ¨æ•¸æ“šã€è²¡å ±ç´°ç¯€æ™‚ä½¿ç”¨ã€‚"
                )
                tools.append(retriever_tool)

            # å»ºç«‹ Agent
            prompt_template = ChatPromptTemplate.from_messages([
                ("system", "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æŠ•è³‡åˆ†æå¸«ã€‚çµåˆã€å³æ™‚æ•¸æ“šã€(è‚¡åƒ¹ã€æ–°è) èˆ‡ ã€å…§éƒ¨æ–‡ä»¶ã€(è‹¥æœ‰) ä¾†å›ç­”ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡ã€‚"),
                ("placeholder", "{chat_history}"),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ])
            
            agent = create_tool_calling_agent(llm, tools, prompt_template)
            agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
            
            response = agent_executor.invoke({"input": prompt})
            answer = response['output']
            
            message_placeholder.markdown(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})
            
        except Exception as e:
            st.error(f"âŒ éŒ¯èª¤: {e}")