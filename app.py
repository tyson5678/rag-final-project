import streamlit as st
import os
import sys
import tempfile
import uuid

# ================= 1. é›²ç«¯è³‡æ–™åº«ä¿®æ­£ =================
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

# ================= 2. é é¢è¨­å®š =================
st.set_page_config(
    page_title="AI æ™ºèƒ½æŠ•è³‡åˆ†æå¸«", 
    page_icon="ğŸ“ˆ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“ˆ AI æ™ºèƒ½æŠ•è³‡åˆ†æå¸«")
st.caption("ğŸš€ é›™å¼•æ“æ¶æ§‹ï¼šæ”¯æ´ Google Gemini èˆ‡ Groq Llama 3")

# ================= 3. åŒ¯å…¥å¿…è¦å¥—ä»¶ =================
try:
    import langchain
    # åŒ¯å…¥å…©å®¶çš„æ¨¡å‹åº«
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_groq import ChatGroq
    
    from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain.prompts import ChatPromptTemplate
    
    from langchain.agents import initialize_agent, AgentType, Tool
    from langchain.chains import RetrievalQA
    import yfinance as yf
    from googlesearch import search as google_search
    
except ImportError as e:
    st.error(f"âŒ ç³»çµ±å•Ÿå‹•å¤±æ•—ï¼åŸå› : {e}")
    st.stop()

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ================= 4. API Key è¨­å®š (é›™é‡‘é‘°) =================
# å˜—è©¦è®€å–å…©å€‹ Keyï¼Œå¦‚æœæ²’æœ‰å°±è¨­ç‚ºç©ºå­—ä¸²ï¼Œç¨å¾Œåœ¨ä»‹é¢æé†’
GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", "")
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "")

# ================= 5. å®šç¾©å·¥å…· (Tools) =================

def get_stock_price_func(symbol: str):
    """æŸ¥è©¢è‚¡ç¥¨åƒ¹æ ¼"""
    try:
        stock = yf.Ticker(symbol)
        info = stock.info
        currency = info.get('currency', 'USD')
        price = info.get('currentPrice') or info.get('regularMarketPrice') or info.get('ask') or 'N/A'
        return f"ã€{symbol}ã€‘ç¾åƒ¹: {price} {currency}"
    except Exception as e:
        return f"æŸ¥è©¢å¤±æ•—: {e}"

def get_google_news_func(query: str):
    """Google æœå°‹"""
    try:
        results = google_search(query, num_results=3, advanced=True)
        output_text = f"ã€Google æœå°‹çµæœ - {query}ã€‘\n"
        count = 0
        for r in results:
            count += 1
            output_text += f"{count}. {r.title}\n   {r.description}\n\n"
        if count == 0: return "æœªæœå°‹åˆ°ç›¸é—œçµæœã€‚"
        return output_text
    except Exception as e:
        return f"æœå°‹å¤±æ•—: {e}"

# ================= 6. æ ¸å¿ƒé‚è¼¯ =================

if "uploader_id" not in st.session_state:
    st.session_state.uploader_id = str(uuid.uuid4())
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vector_db" not in st.session_state:
    st.session_state.vector_db = None
if "processed_files" not in st.session_state:
    st.session_state.processed_files = [] 

def nuke_reset():
    st.session_state.messages = []
    st.session_state.vector_db = None
    st.session_state.processed_files = []
    st.session_state.uploader_id = str(uuid.uuid4()) 

with st.sidebar:
    # ğŸŒŸğŸŒŸğŸŒŸ æ–°å¢ï¼šæ¨¡å‹é¸æ“‡å™¨ (æ•‘å‘½ç¨»è‰) ğŸŒŸğŸŒŸğŸŒŸ
    st.header("ğŸ¤– æ¨¡å‹è¨­å®š")
    model_option = st.selectbox(
        "é¸æ“‡ AI æ¨¡å‹å¼•æ“",
        (
            "Google Gemini 1.5 Flash (æ¨è–¦)", 
            "Groq Llama 3.1 8B (å‚™ç”¨/é«˜é€Ÿ)",
            "Groq Llama 3.3 70B (å¼·å¤§/æ˜“é™æµ)"
        ),
        index=0
    )
    
    st.divider()
    st.header("ğŸ—‚ï¸ è²¡å ±ä¸Šå‚³")
    
    uploaded_files = st.file_uploader(
        "ä¸Šå‚³æ–‡ä»¶", 
        type=["pdf", "docx"], 
        accept_multiple_files=True,
        key=st.session_state.uploader_id 
    )
    
    current_files_sig = [(f.name, f.size) for f in uploaded_files] if uploaded_files else []
    
    if uploaded_files:
        if current_files_sig != st.session_state.processed_files:
            with st.spinner("ğŸ§  è®€å–ä¸¦å‘é‡åŒ–æ–‡ä»¶ (FastEmbed)..."):
                try:
                    all_splits = []
                    for uploaded_file in uploaded_files:
                        file_name = uploaded_file.name
                        file_ext = os.path.splitext(file_name)[1].lower()
                        
                        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
                            tmp_file.write(uploaded_file.getvalue())
                            tmp_path = tmp_file.name

                        if file_ext == ".pdf": loader = PyPDFLoader(tmp_path)
                        elif file_ext == ".docx": loader = Docx2txtLoader(tmp_path)
                        else: continue
                            
                        docs = loader.load()
                        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)
                        splits = text_splitter.split_documents(docs)
                        all_splits.extend(splits)
                        os.remove(tmp_path)

                    if all_splits:
                        embeddings = FastEmbedEmbeddings()
                        unique_collection_name = f"collection_{uuid.uuid4()}"
                        vector_db = Chroma.from_documents(
                            documents=all_splits, 
                            embedding=embeddings,
                            collection_name=unique_collection_name 
                        )
                        st.session_state.vector_db = vector_db
                        st.session_state.processed_files = current_files_sig
                        st.toast(f"âœ… è³‡æ–™åº«å»ºç«‹å®Œæˆï¼", icon="ğŸ“š")
                    else:
                        st.warning("âš ï¸ æª”æ¡ˆå…§å®¹ç‚ºç©º")
                except Exception as e:
                    st.error(f"âŒ éŒ¯èª¤: {e}")
    else:
        if st.session_state.vector_db is not None:
            st.session_state.vector_db = None
            st.session_state.processed_files = []
            st.rerun()

    st.markdown("") 
    if st.button("ğŸ”„ é‡ç½®ç³»çµ±", type="primary", use_container_width=True, on_click=nuke_reset):
        pass

# ================= èŠå¤©ä»‹é¢ =================

if not st.session_state.messages:
    st.info("ğŸ‘‹ æˆ‘æ˜¯ AI æŠ•è³‡åˆ†æå¸«ï¼Œè«‹é¸æ“‡æ¨¡å‹ä¸¦é–‹å§‹æå•ï¼")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è«‹è¼¸å…¥å•é¡Œ..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        try:
            llm = None
            # ğŸŒŸ æ ¹æ“šé¸å–®å‹•æ…‹åˆ‡æ›æ¨¡å‹
            if "Gemini" in model_option:
                if not GOOGLE_API_KEY:
                    st.error("âŒ ç¼ºå°‘ GOOGLE_API_KEYï¼Œè«‹æª¢æŸ¥ Secretsã€‚")
                    st.stop()
                message_placeholder.markdown("ğŸ’ Gemini æ­£åœ¨æ€è€ƒ...")
                llm = ChatGoogleGenerativeAI(
                    google_api_key=GOOGLE_API_KEY,
                    model="gemini-1.5-flash", # å˜—è©¦ç”¨ Flash
                    temperature=0.1,
                    convert_system_message_to_human=True
                )
            elif "Groq" in model_option:
                if not GROQ_API_KEY:
                    st.error("âŒ ç¼ºå°‘ GROQ_API_KEYï¼Œè«‹æª¢æŸ¥ Secretsã€‚")
                    st.stop()
                
                model_name = "llama-3.1-8b-instant" if "8B" in model_option else "llama-3.3-70b-versatile"
                message_placeholder.markdown(f"âš¡ Groq ({model_name}) æ­£åœ¨æ€è€ƒ...")
                
                llm = ChatGroq(
                    groq_api_key=GROQ_API_KEY, 
                    model_name=model_name,
                    temperature=0.1
                )

            # å®šç¾©å·¥å…·
            tools = [
                Tool(name="Stock_Price", func=get_stock_price_func, description="è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼(å¦‚ 2330.TW)ï¼Œå›å‚³å³æ™‚è‚¡åƒ¹ã€‚"),
                Tool(name="Google_Search", func=get_google_news_func, description="è¼¸å…¥æœå°‹é—œéµå­—ï¼Œå›å‚³ç¶²è·¯æ–°èã€‚")
            ]
            
            if st.session_state.vector_db:
                qa = RetrievalQA.from_chain_type(
                    llm=llm,
                    retriever=st.session_state.vector_db.as_retriever(search_kwargs={"k": 5})
                )
                tools.append(
                    Tool(name="Financial_Report_RAG", func=qa.run, description="ç”¨æ–¼æŸ¥è©¢ä½¿ç”¨è€…ä¸Šå‚³çš„è²¡å ±å…§å®¹ã€‚")
                )

            agent = initialize_agent(
                tools, 
                llm, 
                agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
                verbose=False,
                handle_parsing_errors=True
            )
            
            response = agent.run(prompt)
            
            message_placeholder.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
            
        except Exception as e:
            st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
            if "404" in str(e) and "Gemini" in model_option:
                st.warning("âš ï¸ Google æ¨¡å‹é€£ç·šå¤±æ•—ï¼Œè«‹å˜—è©¦åˆ‡æ›åˆ° 'Groq Llama 3.1 8B'ï¼")
            elif "429" in str(e):
                st.warning("âš ï¸ é¡åº¦å·²æ»¿ï¼Œè«‹åˆ‡æ›å…¶ä»–æ¨¡å‹ï¼")

# ================= 4. API Key è¨­å®š (é›™é‡‘é‘°) =================
GOOGLE_API_KEY = "ä½ çš„_AIza_é–‹é ­_Key"
GROQ_API_KEY = "ä½ çš„_gsk_é–‹é ­_Key"