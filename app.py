import streamlit as st
import os
import sys
import tempfile
import uuid

# ================= 1. é›²ç«¯è³‡æ–™åº«ä¿®æ­£ =================
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

# ================= 2. é é¢è¨­å®š =================
st.set_page_config(
    page_title="AI æ·±åº¦çŸ¥è­˜åº«", 
    page_icon="ğŸ§ ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("æ·±åº¦æ–‡ä»¶åˆ†æåŠ©æ‰‹")
st.caption("ğŸš€ Powered by Meta Llama 3.3 & Groq Inference Engine | Enterprise-Grade RAG System")

# ================= 3. å®‰å…¨è¼‰å…¥å¥—ä»¶ =================
try:
    import langchain
    from langchain_groq import ChatGroq
    from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_chroma import Chroma
    try:
        from langchain.chains import create_retrieval_chain
        from langchain.chains.combine_documents import create_stuff_documents_chain
    except ImportError:
        from langchain.chains.retrieval import create_retrieval_chain
    from langchain_core.prompts import ChatPromptTemplate
    
except ImportError as e:
    st.error(f"âŒ ç³»çµ±å•Ÿå‹•å¤±æ•—ï¼åŸå› : {e}")
    st.stop()

os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ================= 4. API Key =================
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
except:
    GROQ_API_KEY = "è«‹å¡«å…¥Key"

# ================= 5. æ ¸å¿ƒé‚è¼¯ =================

# åˆå§‹åŒ–è®Šæ•¸
if "uploader_id" not in st.session_state:
    st.session_state.uploader_id = str(uuid.uuid4())
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vector_db" not in st.session_state:
    st.session_state.vector_db = None
if "processed_files" not in st.session_state:
    st.session_state.processed_files = [] # ğŸŒŸ æ–°å¢ï¼šç”¨ä¾†è¨˜éŒ„ç›®å‰å·²ç¶“è™•ç†éå“ªäº›æª”æ¡ˆ

def nuke_reset():
    """æ ¸å½ˆç´šé‡ç½®"""
    st.session_state.messages = []
    st.session_state.vector_db = None
    st.session_state.processed_files = []
    st.session_state.uploader_id = str(uuid.uuid4()) 

with st.sidebar:
    st.header("ğŸ—‚ï¸ è³‡æ–™ä¸Šå‚³")
    
    uploaded_files = st.file_uploader(
        "ä¸Šå‚³æ–‡ä»¶ (PDF / Word)", 
        type=["pdf", "docx"], 
        accept_multiple_files=True,
        key=st.session_state.uploader_id 
    )
    
    # ğŸŒŸ é‚è¼¯ä¿®æ­£é‡é»ï¼š
    # 1. ç”¢ç”Ÿä¸€å€‹ã€Œç›®å‰çš„æª”æ¡ˆæ¸…å–®æŒ‡ç´‹ã€(åŒ…å«æª”åå’Œå¤§å°)ï¼Œç”¨ä¾†åˆ¤æ–·æª”æ¡ˆæœ‰æ²’æœ‰è®Š
    current_files_sig = [(f.name, f.size) for f in uploaded_files] if uploaded_files else []
    
    # 2. åˆ¤æ–·é‚è¼¯ï¼š
    #    æƒ…æ³ A: æœ‰ä¸Šå‚³æª”æ¡ˆï¼Œè€Œä¸”è·Ÿä¸Šæ¬¡è™•ç†çš„ä¸ä¸€æ¨£ -> åŸ·è¡Œé‡æ–°è™•ç†
    #    æƒ…æ³ B: æ²’æœ‰ä¸Šå‚³æª”æ¡ˆ -> æ¸…ç©ºè³‡æ–™åº«
    
    if uploaded_files:
        if current_files_sig != st.session_state.processed_files:
            # ç™¼ç¾æª”æ¡ˆæœ‰è®Šå‹•ï¼é‡æ–°å»ºç«‹è³‡æ–™åº«
            with st.spinner("ğŸ§  åµæ¸¬åˆ°æ–‡ä»¶è®Šå‹•ï¼Œæ­£åœ¨é‡æ–°åˆ†æ..."):
                try:
                    all_splits = []
                    for uploaded_file in uploaded_files:
                        file_name = uploaded_file.name
                        file_ext = os.path.splitext(file_name)[1].lower()
                        
                        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
                            tmp_file.write(uploaded_file.getvalue())
                            tmp_path = tmp_file.name

                        if file_ext == ".pdf":
                            loader = PyPDFLoader(tmp_path)
                        elif file_ext == ".docx":
                            loader = Docx2txtLoader(tmp_path)
                        else:
                            continue
                            
                        docs = loader.load()
                        for doc in docs:
                            doc.metadata["source_filename"] = file_name
                        
                        text_splitter = RecursiveCharacterTextSplitter(
                            chunk_size=800, 
                            chunk_overlap=150,
                            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""]
                        )
                        splits = text_splitter.split_documents(docs)
                        all_splits.extend(splits)
                        os.remove(tmp_path)

                    if all_splits:
                        # ğŸŒŸ éŒ¯èª¤ä¿®æ­£é»ï¼šå¼·åˆ¶ä½¿ç”¨ CPU é¿å… Meta Tensor éŒ¯èª¤
                        embeddings = HuggingFaceEmbeddings(
                            model_name="sentence-transformers/all-MiniLM-L6-v2",
                            model_kwargs={'device': 'cpu'}
                        )
                        vector_db = Chroma.from_documents(documents=all_splits, embedding=embeddings)
                        
                        # æ›´æ–°ç‹€æ…‹
                        st.session_state.vector_db = vector_db
                        st.session_state.processed_files = current_files_sig # è¨˜éŒ„ç¾åœ¨è™•ç†å¥½çš„æª”æ¡ˆ
                        st.toast(f"âœ… è³‡æ–™åº«å·²æ›´æ–°ï¼", icon="ğŸ”„")
                    else:
                        st.warning("âš ï¸ æª”æ¡ˆå…§å®¹ç‚ºç©º")
                except Exception as e:
                    st.error(f"âŒ éŒ¯èª¤: {e}")
    else:
        # å¦‚æœä½¿ç”¨è€…æŠŠæª”æ¡ˆéƒ½åˆªå…‰äº†ï¼Œä¹Ÿè¦æŠŠè³‡æ–™åº«æ¸…ç©º
        if st.session_state.vector_db is not None:
            st.session_state.vector_db = None
            st.session_state.processed_files = []
            st.rerun()

    st.divider()
    st.header("âš™ï¸ åƒæ•¸")
    
    temperature = st.slider("temperatureï¼ˆæ¨¡å‹å‰µæ„åº¦ï¼‰", 0.0, 1.0, 0.1, 0.1)
    k_value = st.slider("kå€¼ï¼ˆé–±è®€å»£åº¦ï¼‰", 2, 20, 8)

    st.markdown("")
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå°è©±", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
        
    st.markdown("") 
    if st.button("ğŸ”„ é‡ç½®æ–‡ä»¶", type="primary", use_container_width=True, on_click=nuke_reset):
        pass

# ================= èŠå¤©ä»‹é¢ =================

if not st.session_state.messages:
    st.info("ğŸ‘‹ è«‹ä¸Šå‚³æ–‡ä»¶é–‹å§‹ä½¿ç”¨ã€‚")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è«‹è¼¸å…¥å•é¡Œ..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    if st.session_state.vector_db:
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            try:
                llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name="llama-3.3-70b-versatile", temperature=temperature)
                
                qa_prompt = ChatPromptTemplate.from_template("""
                ä½ æ˜¯ä¸€å€‹é«˜éšå­¸è¡“ç ”ç©¶å“¡ã€‚è«‹æ ¹æ“šä»¥ä¸‹ã€ä¸Šä¸‹æ–‡ã€‘å›ç­”å•é¡Œã€‚
                1. è‹¥ç„¡ç›¸é—œè³‡è¨Šï¼Œè«‹èª å¯¦å›ç­”ã€Œæ–‡ä»¶ä¸­æœªæåŠã€ã€‚
                2. è«‹ç”¨å°ç£ç¹é«”ä¸­æ–‡å›ç­”ã€‚
                ã€ä¸Šä¸‹æ–‡ã€‘:{context}
                ã€å•é¡Œã€‘:{input}
                """)

                retriever = st.session_state.vector_db.as_retriever(search_kwargs={"k": k_value})
                document_chain = create_stuff_documents_chain(llm, qa_prompt)
                retrieval_chain = create_retrieval_chain(retriever, document_chain)
                
                response = retrieval_chain.invoke({"input": prompt})
                answer = response['answer']
                
                message_placeholder.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
                
                with st.expander("ğŸ“š åƒè€ƒä¾†æº"):
                    for i, doc in enumerate(response['context']):
                        st.caption(f"ğŸ“„ **{doc.metadata.get('source_filename')}** (p.{doc.metadata.get('page',0)+1})")
                        st.text(doc.page_content[:100] + "...")
                        st.divider()

            except Exception as e:
                st.error(f"âŒ éŒ¯èª¤: {e}")
    else:
        with st.chat_message("assistant"):
            st.warning("âš ï¸ è«‹å…ˆä¸Šå‚³æ–‡ä»¶ï¼Œæˆ‘æ‰èƒ½å›ç­”å•é¡Œå–”ï¼")